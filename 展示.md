### 1: 项目概述

- 介绍项目的背景和目标
- 提及使用的技术和工具

```python
# 项目概述
# ...

# 提及使用的技术和工具
# ...
```

### 2: 数据预处理

- 描述 `DataProcess` 函数的作用
- 展示数据预处理的步骤和目的

```python
# 数据预处理
# 数据预处理 - DataProcess 函数
def DataProcess():
    # 文件路径
    path = 'D:\\code\\python_p\\train.csv'
    
    # 使用 Pandas 阅读器打开 CSV 文件
    df = pd.read_csv(path)
    
    # 空值填充
    df = df.fillna(0)

    # 分别提取标签和特征数据
    df_y = df[['label']]
    df_x = df[['feature']]

    # 将 label 和 feature 数据写入 CSV 文件
    df_y.to_csv('label.csv', index=False, header=False)
    df_x.to_csv('data.csv', index=False, header=False)

    # 指定存放图片的路径
    path = 'D:\\code\\python_p\\images'

    # 读取像素数据
    data = np.loadtxt('data.csv')

    # 按行取数据
    for i in range(2000):
        face_array = data[i, :].reshape((48, 48))  # 转成图像矩阵给 cv2 处理

        # 根据条件将图片保存到不同文件夹
        if i < 1800:
            cv2.imwrite(path + '//train_data//' + '{0}.jpg'.format(i), face_array)  # 转换为 jpg 并保存
        else:
            cv2.imwrite(path + '//test_data//' + '{0}.jpg'.format(i), face_array)  # 转换为 jpg 并保存

    
# 在PPT上展示数据预处理的步骤和目的
```

### 3: 数据标签生成

-  `data_label` 函数的功能
  - 通过继承 PyTorch 的 `Dataset` 类，实现了 `__init__` 初始化方法、`__getitem__` 获取某一样本的方法以及 `__len__` 获取数据集样本个数的方法。展示了数据读取、灰度处理、直方图均衡化、像素值标准化等步骤。


```python
# 数据标签生成
# 数据与标签关联 - data_label 函数
def data_label(path):
    # 读取 label 文件
    df_label = pd.read_csv('label.csv', header=None)

    # 查看文件夹下所有文件
    files_dir = os.listdir(path)

    # 用于存放图片名
    path_list = []

    # 用于存放图片对应的 label
    label_list = []

    # 遍历该文件夹下的所有文件
    for files_dir in files_dir:
        # 如果某文件是图片，则其文件名以及对应的 label 取出，分别放入 path_list 和 label_list 这两个列表中
        if os.path.splitext(files_dir)[1] == ".jpg":  # 路径切割，将文件名和后缀名作切割后保存为列表形式
            path_list.append(files_dir)  # 如果是 .jpg 文件就添加入 path_list 路径列表
            index = int(os.path.splitext(files_dir)[0])  # 将图片文件名按数值类型转存
            label_list.append(df_label.iat[index, 0])  # 将文件编号填入

    # 将两个列表写进 dataset.csv 文件
    path_s = pd.Series(path_list)
    label_s = pd.Series(label_list)
    df = pd.DataFrame()
    df['path'] = path_s
    df['label'] = label_s
    df.to_csv(path + '\\dataset.csv', index=False, header=False)  # df 保存，命名为 dataset.csv

```

### 4: 数据集加载

- 介绍 `FaceDataset` 类的作用
- 展示数据集加载的步骤和预处理操作

```python

class FaceDataset(data.Dataset):
    # 初始化
    def __init__(self, root):  # root 为 train 或 val 文件夹地址
        super(FaceDataset, self).__init__()  # 调用父类的初始化函数
        self.root = root
        
        # 读取 data - label 对照表中的内容
        df_path = pd.read_csv(root + '\\dataset.csv', header=None, usecols=[0])
        df_label = pd.read_csv(root + '\\dataset.csv', header=None, usecols=[1])
        
        # 将其中内容放入 numpy，方便后期索引
        self.path = np.array(df_path)[:, 0]
        self.label = np.array(df_label)[:, 0]

    # 读取某幅图片，item 为索引号
    def __getitem__(self, item):
        face = cv2.imread(self.root + '\\' + self.path[item])  # 读取图片

        # 读取单通道灰度图
        face_gray = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)  # 单通道=灰度，三通道-RGB彩色

        # 高斯模糊
        # face_Gus = cv2.GaussianBlur(face_gray, (3, 3), 0)

        # 直方图均衡化
        face_hist = cv2.equalizeHist(face_gray)

        # 像素值标准化，0-255 的像素范围转成 0-1 范围来描述
        face_normalized = face_hist.reshape(1, 48, 48) / 255.0

        # 用于训练的数据需要为 tensor 类型
        face_tensor = torch.from_numpy(face_normalized)  # 将 numpy 中的 ndarray 转换成 pytorch 中的 tensor
        face_tensor = face_tensor.type('torch.FloatTensor')  # Tensor 转 FloatTensor
        label = self.label[item]
        return face_tensor, label

    # 获取数据集样本个数
    def __len__(self):
        return self.path.shape[0]
```

### 5: 模型定义
- 描述 `FaceCNN` 类的结构
- 强调模型中的卷积层、池化层和全连接层

```python
# 模型定义
class FaceCNN(nn.Module):
    # ...
    
# 在PPT上展示模型结构的描述
```

### 6: 训练模型
- 说明 `train` 函数的功能和参数
- 展示模型训练的步骤和关键代码片段

```python
# 模型训练 - train 函数
def train(model, train_dataset, val_dataset, batch_size, epochs, learning_rate, wt_decay):
    # 如果传入的模型为 None，则实例化一个新模型
    if model is None:
        model = FaceCNN()
    # 载入数据并分割 batch
    train_loader = data.DataLoader(train_dataset, batch_size)
    # 损失函数
    loss_function = nn.CrossEntropyLoss()
    # 优化器
    optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=wt_decay)
    # 学习率衰减
    # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size= 10, gamma= 0.8)

    # 逐轮训练
    for epoch in range(epochs):
        # 记录损失值
        loss_rate = 0
        # scheduler.step()
        # 注意 dropout 网络结构下训练和 test 模式下是不一样的结构
        model.train()  # 模型训练，调用 Modlue 类提供的 train() 方法切换到 train 状态

        # for images, labels in train_loader:
        #     # 梯度清零
        #     optimizer.zero_grad()
        #     # 前向传播
        #     output = model.forward(images)
        #     # 误差计算
        #     loss_rate = loss_function(output, labels)
        #     # 误差的反向传播
        #     loss_rate.backward()
        #     # 更新参数
        #     optimizer.step()

        # 梯度清零
        optimizer.zero_grad()
        # 随机选择一个 batch 的数据
        images, labels = next(iter(train_loader))
        # 前向传播
        output = model.forward(images)
        # 误差计算
        loss_rate = loss_function(output, labels)
        # 误差的反向传播
        loss_rate.backward()
        # 更新参数
        optimizer.step()

        # 打印每轮的损失
        print('After {} epochs , '.format(epoch + 1))
        print('After {} epochs , the loss_rate is : '.format(epoch + 1), loss_rate.item())
        # 在每轮结束后记录损失率和正确率
        loss_rates.append(loss_rate.item())
        acc_train = validate(model, train_dataset, batch_size)
        acc_val = validate(model, val_dataset, batch_size)
        acc_train_list.append(acc_train)
        acc_val_list.append(acc_val)
        # if epoch % 5 == 0:
        #     model.eval()  # 模型评估,切换到 test 状态继续执行
        #     acc_train = validate(model, train_dataset, batch_size)
        #     acc_val = validate(model, val_dataset, batch_size)
        #     print('After {} epochs , the acc_train is : '.format(epoch + 1), acc_train)
        #     print('After {} epochs , the acc_val is : '.format(epoch + 1), acc_val)

    return model

```

### 7: 主函数

- 描述 `main` 函数的作用
- 展示主函数中的数据预处理、数据集加载和模型训练的调用

```python
# 主函数 - main 函数
def main():
    # 数据预处理
    # 可以添加一个检查数据预处理是否已经执行的条件
    images_dir = 'D:\\code\\python_p\\images'

    # if not os.path.exists(images_dir) or not os.listdir(images_dir):
    # DataProcess()
    #
    # # if not os.path.exists('D:\\code\\python_p\\images\\train_data\\dataset.csv'):
    # train_path = 'D:\\code\\python_p\\images\\train_data'
    # data_label(train_path)
    #
    # # 检查数据预处理是否已经执行
    # # if not os.path.exists('D:\\code\\python_p\\images\\test_data\\dataset.csv'):
    # val_path = 'D:\\code\\python_p\\images\\test_data'
    # data_label(val_path)
    #
    # 数据集的使用
    train_dataset = FaceDataset(root='D:\\code\\python_p\\images\\train_data')
    val_dataset = FaceDataset(root='D:\\code\\python_p\\images\\test_data')

    # 加载已保存的模型
    model = None
    # if os.path.exists('model_net1.pk1'):
    # model = torch.load('model_net1.pk1')

    # 继续训练
    model = train(model, train_dataset, val_dataset, batch_size=128, epochs=200, learning_rate=0.1, wt_decay=0)

    # 保存模型
    torch.save(model, 'model_net1.pk1')

```

### 8: 结果展示
- 展示训练过程中的损失率和正确率的图表
- 模型在训练集和验证集上的性能
- ![image-20231212224627218](C:\Users\hzt\AppData\Roaming\Typora\typora-user-images\image-20231212224627218.png)

```python
# 结果展示
epochs = list(range(1, 201))  # 你的迭代次数范围
plot_metrics(loss_rates, acc_train_list, acc_val_list, epochs)
    
```

